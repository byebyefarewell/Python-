{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models, regularizers\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "art_train_dir = 'C:/Data/DeepLearning/artist/train'\n",
    "art_validation_dir = 'C:/Data/DeepLearning/artist/validation' # 데이터에 있는 test파일의 이름을 validation으로 교체\n",
    "impression_train_dir = os.path.join(art_train_dir,'impressionism')\n",
    "impression_validation_dir = os.path.join(art_validation_dir,'impressionism')\n",
    "\n",
    "#os.mkdir(impression_train_dir)\n",
    "#os.mkdir(impression_validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(directory=art_train_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')\n",
    "validation_generator=validation_datagen.flow_from_directory(directory=art_validation_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32, \n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                401440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 789,988\n",
      "Trainable params: 789,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense, Dropout\n",
    "from keras import models\n",
    "art_model=models.Sequential()\n",
    "art_model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "art_model.add(MaxPooling2D(2,2))\n",
    "art_model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "art_model.add(MaxPooling2D(2,2))\n",
    "art_model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "art_model.add(MaxPooling2D(2,2))\n",
    "art_model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "art_model.add(MaxPooling2D(2,2))\n",
    "art_model.add(Dropout(0.3))\n",
    "art_model.add(Flatten())\n",
    "art_model.add(Dense(32,activation='relu'))\n",
    "art_model.add(Dense(4,activation='softmax'))\n",
    "art_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opt=optimizers.RMSprop(lr=1e-4)\n",
    "art_model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.3477 - acc: 0.3281 - val_loss: 1.3694 - val_acc: 0.2500\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.2771 - acc: 0.3984 - val_loss: 1.1898 - val_acc: 0.4258\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.1797 - acc: 0.4609 - val_loss: 1.1758 - val_acc: 0.4453\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.1286 - acc: 0.4844 - val_loss: 1.3646 - val_acc: 0.3867\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.0684 - acc: 0.5342 - val_loss: 1.3631 - val_acc: 0.4453\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.0348 - acc: 0.5566 - val_loss: 1.1450 - val_acc: 0.4727\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.0250 - acc: 0.5342 - val_loss: 1.0595 - val_acc: 0.4883\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.0066 - acc: 0.5537 - val_loss: 1.1940 - val_acc: 0.4102\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.9844 - acc: 0.5527 - val_loss: 1.0956 - val_acc: 0.5273\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.9725 - acc: 0.5664 - val_loss: 1.1106 - val_acc: 0.5273\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.9484 - acc: 0.5918 - val_loss: 1.1336 - val_acc: 0.5352\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 38s 1s/step - loss: 0.9236 - acc: 0.6035 - val_loss: 1.1313 - val_acc: 0.4961\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.9473 - acc: 0.5889 - val_loss: 1.3191 - val_acc: 0.4922\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 38s 1s/step - loss: 0.9025 - acc: 0.6133 - val_loss: 1.1706 - val_acc: 0.5508\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 38s 1s/step - loss: 0.8988 - acc: 0.6133 - val_loss: 1.0788 - val_acc: 0.5312\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.8906 - acc: 0.6104 - val_loss: 1.0397 - val_acc: 0.5117\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8633 - acc: 0.6221 - val_loss: 1.1880 - val_acc: 0.4766\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.8854 - acc: 0.6260 - val_loss: 1.0107 - val_acc: 0.5156\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.8448 - acc: 0.6455 - val_loss: 1.1209 - val_acc: 0.5156\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.8447 - acc: 0.6416 - val_loss: 0.9484 - val_acc: 0.5508\n"
     ]
    }
   ],
   "source": [
    "art_result=art_model.fit_generator(train_generator,steps_per_epoch=1024//32,\n",
    "                                          epochs=20,\n",
    "                                          validation_data=validation_generator,\n",
    "                                          validation_steps=256//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,634,276\n",
      "Trainable params: 1,634,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense, Dropout\n",
    "from keras import models, regularizers\n",
    "aug_model=models.Sequential()\n",
    "aug_model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "aug_model.add(MaxPooling2D(2,2))\n",
    "aug_model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "aug_model.add(MaxPooling2D(2,2))\n",
    "aug_model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "aug_model.add(MaxPooling2D(2,2))\n",
    "aug_model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "aug_model.add(MaxPooling2D(2,2))\n",
    "aug_model.add(Conv2D(512,(3,3),activation='relu'))\n",
    "aug_model.add(MaxPooling2D(2,2))\n",
    "aug_model.add(Flatten())\n",
    "aug_model.add(Dropout(0.6))\n",
    "aug_model.add(Dense(32,activation='relu'))\n",
    "aug_model.add(Dense(4,activation='sigmoid', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))\n",
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Reshape, Conv2DTranspose, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                524320    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 912,868\n",
      "Trainable params: 912,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import instancenormalization\n",
    "inputs = Input(shape=(150, 150, 3))\n",
    "x = Conv2D(32, (3, 3))(inputs)\n",
    "x = instancenormalization.InstanceNormalization(\n",
    "    axis=-1,center=False, scale=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x =  MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x =  MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x =  MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x = Dense(4,activation='softmax')(x)\n",
    "aug_model = Model(inputs, x)\n",
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_aug_gen=ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=55, \n",
    "                                 width_shift_range=0.3, \n",
    "                                 height_shift_range=0.1,\n",
    "                                 shear_range=0.5,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='wrap')\n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 16\n",
    "train_generator=data_aug_gen.flow_from_directory(art_train_dir ,target_size=(150,150),\n",
    "                                              batch_size=batch_size, class_mode='categorical')\n",
    "validation_generator=validation_datagen.flow_from_directory(art_validation_dir ,target_size=(150,150),\n",
    "                                              batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "350/350 [==============================] - 319s 911ms/step - loss: 1.1997 - acc: 0.4389 - val_loss: 1.2261 - val_acc: 0.4219\n",
      "Epoch 2/20\n",
      "350/350 [==============================] - 309s 882ms/step - loss: 1.0829 - acc: 0.5139 - val_loss: 1.1164 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "350/350 [==============================] - 315s 899ms/step - loss: 1.0020 - acc: 0.5632 - val_loss: 1.1513 - val_acc: 0.5664\n",
      "Epoch 4/20\n",
      "350/350 [==============================] - 324s 927ms/step - loss: 0.9563 - acc: 0.5979 - val_loss: 1.0327 - val_acc: 0.5703\n",
      "Epoch 5/20\n",
      "350/350 [==============================] - 312s 892ms/step - loss: 0.9245 - acc: 0.6064 - val_loss: 1.0016 - val_acc: 0.5977\n",
      "Epoch 6/20\n",
      "350/350 [==============================] - 308s 881ms/step - loss: 0.8829 - acc: 0.6257 - val_loss: 1.0640 - val_acc: 0.5977\n",
      "Epoch 7/20\n",
      "350/350 [==============================] - 312s 892ms/step - loss: 0.8473 - acc: 0.6382 - val_loss: 1.0454 - val_acc: 0.5625\n",
      "Epoch 8/20\n",
      "350/350 [==============================] - 344s 982ms/step - loss: 0.8354 - acc: 0.6513 - val_loss: 1.4860 - val_acc: 0.5078\n",
      "Epoch 9/20\n",
      "350/350 [==============================] - 306s 874ms/step - loss: 0.7985 - acc: 0.6634 - val_loss: 0.9404 - val_acc: 0.6328\n",
      "Epoch 10/20\n",
      "350/350 [==============================] - 306s 874ms/step - loss: 0.7670 - acc: 0.6782 - val_loss: 1.0026 - val_acc: 0.5898\n",
      "Epoch 11/20\n",
      "350/350 [==============================] - 305s 871ms/step - loss: 0.7467 - acc: 0.6882 - val_loss: 1.2692 - val_acc: 0.5664\n",
      "Epoch 12/20\n",
      "350/350 [==============================] - 307s 876ms/step - loss: 0.7194 - acc: 0.6973 - val_loss: 1.4666 - val_acc: 0.5664\n",
      "Epoch 13/20\n",
      "350/350 [==============================] - 311s 888ms/step - loss: 0.7004 - acc: 0.7071 - val_loss: 1.2733 - val_acc: 0.5273\n",
      "Epoch 14/20\n",
      "350/350 [==============================] - 313s 894ms/step - loss: 0.6795 - acc: 0.7143 - val_loss: 1.3344 - val_acc: 0.5664\n",
      "Epoch 15/20\n",
      "350/350 [==============================] - 309s 882ms/step - loss: 0.6577 - acc: 0.7298 - val_loss: 1.1902 - val_acc: 0.6016\n",
      "Epoch 16/20\n",
      "350/350 [==============================] - 304s 868ms/step - loss: 0.6485 - acc: 0.7343 - val_loss: 1.2263 - val_acc: 0.5859\n",
      "Epoch 17/20\n",
      "350/350 [==============================] - 305s 872ms/step - loss: 0.6155 - acc: 0.7430 - val_loss: 1.1523 - val_acc: 0.5898\n",
      "Epoch 18/20\n",
      "350/350 [==============================] - 305s 872ms/step - loss: 0.6140 - acc: 0.7446 - val_loss: 1.3166 - val_acc: 0.5625\n",
      "Epoch 19/20\n",
      "350/350 [==============================] - 306s 875ms/step - loss: 0.5861 - acc: 0.7513 - val_loss: 1.5452 - val_acc: 0.5234\n",
      "Epoch 20/20\n",
      "350/350 [==============================] - 305s 871ms/step - loss: 0.5613 - acc: 0.7654 - val_loss: 1.4347 - val_acc: 0.5547\n"
     ]
    }
   ],
   "source": [
    "aug_model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "aug_result=aug_model.fit_generator(train_generator,steps_per_epoch=350,\n",
    "                                   epochs=20,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=256//16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_base=VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "vgg_base.summary()\n",
    "vgg_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 33,596,228\n",
      "Trainable params: 18,881,540\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "additional_model = models.Sequential()\n",
    "additional_model.add(vgg_base)\n",
    "additional_model.add(Flatten())\n",
    "additional_model.add(Dense(2048, activation='relu',\n",
    "                           kernel_regularizer=\n",
    "                           regularizers.l1_l2(l1=0.001, l2=0.01)))\n",
    "additional_model.add(Dropout(0.5))\n",
    "additional_model.add(Dense(1024, activation='relu',\n",
    "                           kernel_regularizer=\n",
    "                           regularizers.l1_l2(l1=0.001, l2=0.01)))\n",
    "additional_model.add(Dropout(0.5))\n",
    "additional_model.add(Dense(4, activation='softmax', \n",
    "                           kernel_regularizer=\n",
    "                           regularizers.l1_l2(l1=0.001, l2=0.01)))\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 238.6977 - acc: 0.4588 - val_loss: 186.9500 - val_acc: 0.5943\n",
      "Epoch 2/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 145.4361 - acc: 0.5904 - val_loss: 108.6781 - val_acc: 0.6137\n",
      "Epoch 3/20\n",
      "350/350 [==============================] - 485s 1s/step - loss: 82.2249 - acc: 0.6243 - val_loss: 60.5439 - val_acc: 0.6240\n",
      "Epoch 4/20\n",
      "350/350 [==============================] - 485s 1s/step - loss: 48.0585 - acc: 0.6468 - val_loss: 38.7576 - val_acc: 0.6025\n",
      "Epoch 5/20\n",
      "350/350 [==============================] - 486s 1s/step - loss: 32.2899 - acc: 0.6632 - val_loss: 26.8804 - val_acc: 0.6127\n",
      "Epoch 6/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 22.7478 - acc: 0.6525 - val_loss: 19.2754 - val_acc: 0.6107\n",
      "Epoch 7/20\n",
      "350/350 [==============================] - 486s 1s/step - loss: 16.6770 - acc: 0.6568 - val_loss: 14.5588 - val_acc: 0.5645\n",
      "Epoch 8/20\n",
      "350/350 [==============================] - 484s 1s/step - loss: 12.7370 - acc: 0.6561 - val_loss: 11.2250 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "350/350 [==============================] - 482s 1s/step - loss: 9.9140 - acc: 0.6539 - val_loss: 8.8485 - val_acc: 0.6127\n",
      "Epoch 10/20\n",
      "350/350 [==============================] - 482s 1s/step - loss: 7.8514 - acc: 0.6525 - val_loss: 7.1275 - val_acc: 0.5266\n",
      "Epoch 11/20\n",
      "350/350 [==============================] - 484s 1s/step - loss: 6.3244 - acc: 0.6554 - val_loss: 5.7992 - val_acc: 0.5461\n",
      "Epoch 12/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 5.2234 - acc: 0.6475 - val_loss: 4.8547 - val_acc: 0.5758\n",
      "Epoch 13/20\n",
      "350/350 [==============================] - 482s 1s/step - loss: 4.3994 - acc: 0.6380 - val_loss: 4.0930 - val_acc: 0.5963\n",
      "Epoch 14/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 3.7674 - acc: 0.6363 - val_loss: 3.5715 - val_acc: 0.5676\n",
      "Epoch 15/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 3.2924 - acc: 0.6280 - val_loss: 3.1623 - val_acc: 0.5605\n",
      "Epoch 16/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 2.9210 - acc: 0.6339 - val_loss: 2.8375 - val_acc: 0.5635\n",
      "Epoch 17/20\n",
      "350/350 [==============================] - 483s 1s/step - loss: 2.6437 - acc: 0.6425 - val_loss: 2.5661 - val_acc: 0.6004\n",
      "Epoch 18/20\n",
      "350/350 [==============================] - 484s 1s/step - loss: 2.4322 - acc: 0.6263 - val_loss: 2.3759 - val_acc: 0.5963\n",
      "Epoch 19/20\n",
      "350/350 [==============================] - 485s 1s/step - loss: 2.2646 - acc: 0.6227 - val_loss: 2.2328 - val_acc: 0.5779\n",
      "Epoch 20/20\n",
      "350/350 [==============================] - 488s 1s/step - loss: 2.1324 - acc: 0.6220 - val_loss: 2.1104 - val_acc: 0.6045\n"
     ]
    }
   ],
   "source": [
    "additional_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    "aug_vgg_result=additional_model.fit_generator(train_generator,steps_per_epoch=350,\n",
    "                                   epochs=20,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=990//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(directory=art_train_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')\n",
    "validation_generator=validation_datagen.flow_from_directory(directory=art_validation_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 83s 3s/step - loss: 289.2587 - acc: 0.3418 - val_loss: 282.3050 - val_acc: 0.5781\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 83s 3s/step - loss: 276.8951 - acc: 0.4414 - val_loss: 270.7426 - val_acc: 0.6211\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 83s 3s/step - loss: 265.4532 - acc: 0.4854 - val_loss: 259.4452 - val_acc: 0.6094\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 88s 3s/step - loss: 254.1716 - acc: 0.5459 - val_loss: 248.2888 - val_acc: 0.5977\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 85s 3s/step - loss: 243.1570 - acc: 0.5684 - val_loss: 237.4121 - val_acc: 0.6680\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 86s 3s/step - loss: 232.3649 - acc: 0.5889 - val_loss: 226.8206 - val_acc: 0.6562\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 92s 3s/step - loss: 221.8552 - acc: 0.6016 - val_loss: 216.4646 - val_acc: 0.6680\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 84s 3s/step - loss: 211.6017 - acc: 0.6094 - val_loss: 206.3699 - val_acc: 0.6484\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 79s 2s/step - loss: 201.5991 - acc: 0.6318 - val_loss: 196.5322 - val_acc: 0.6797\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 191.8683 - acc: 0.6553 - val_loss: 186.9716 - val_acc: 0.6641\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 78s 2s/step - loss: 182.4272 - acc: 0.6953 - val_loss: 177.6367 - val_acc: 0.7031\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 173.2753 - acc: 0.6758 - val_loss: 168.7330 - val_acc: 0.6523\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 164.4092 - acc: 0.6904 - val_loss: 160.0198 - val_acc: 0.6797\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 155.8701 - acc: 0.6738 - val_loss: 151.6201 - val_acc: 0.6484\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 147.5848 - acc: 0.7109 - val_loss: 143.4794 - val_acc: 0.6719\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 78s 2s/step - loss: 139.6094 - acc: 0.7061 - val_loss: 135.6631 - val_acc: 0.6719\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 78s 2s/step - loss: 131.9338 - acc: 0.7188 - val_loss: 128.1579 - val_acc: 0.6836\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 77s 2s/step - loss: 124.5183 - acc: 0.7354 - val_loss: 120.8697 - val_acc: 0.6914\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 82s 3s/step - loss: 117.3503 - acc: 0.7275 - val_loss: 113.8797 - val_acc: 0.6992\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 80s 3s/step - loss: 110.5061 - acc: 0.7451 - val_loss: 107.1539 - val_acc: 0.7109\n"
     ]
    }
   ],
   "source": [
    "additional_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    "history = additional_model.fit_generator(train_generator, \n",
    "            steps_per_epoch=1024//32, \n",
    "            epochs=20, \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=256//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_aug_gen=ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=55, \n",
    "                                 width_shift_range=0.3, \n",
    "                                 height_shift_range=0.1,\n",
    "                                 shear_range=0.5,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='reflect')\n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 16\n",
    "train_generator=data_aug_gen.flow_from_directory(art_train_dir ,target_size=(150,150),\n",
    "                                              batch_size=batch_size, class_mode='categorical')\n",
    "validation_generator=validation_datagen.flow_from_directory(art_validation_dir ,target_size=(150,150),\n",
    "                                              batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
